# ğŸ§  Local AI Assistant (Desktop App)

A **desktop-based Local AI Assistant** built using **Python + PyQt6** that connects to **Ollama** to run LLMs locally.
The application supports **multi-chat sessions, streaming AI responses, voice input, text-to-speech output, and document uploads** (TXT, PDF, DOCX).

This project allows users to interact with local AI models **without internet dependency for inference**, ensuring privacy and low latency.

---

## âœ¨ Features

* ğŸ§  **Local LLM Chat (via Ollama)**
* ğŸ”„ **Streaming AI responses (real-time typing effect)**
* ğŸ’¬ **Multiple chat sessions with history**
* ğŸ¤ **Voice input using Speech Recognition**
* ğŸ”Š **Text-to-Speech (Read AI responses aloud)**
* ğŸ“„ **Upload & read files** (`.txt`, `.pdf`, `.docx`)
* ğŸ“‹ **Copy responses to clipboard**
* ğŸ¨ **Smooth UI animations**
* ğŸ”Œ **Offline-first (except speech recognition)**

---

## ğŸ—ï¸ Architecture Overview

* **Frontend/UI**: PyQt6
* **AI Backend**: Ollama REST API (`/api/chat`)
* **Voice Input**: Google Speech Recognition (via `speech_recognition`)
* **Voice Output**: `pyttsx3` (offline TTS)
* **Threading**: `QThread` for non-blocking UI
* **Streaming**: Server-Sent JSON chunks from Ollama

---

## ğŸ“¦ Requirements

### 1ï¸âƒ£ System Requirements

* OS: **Windows / Linux / macOS**
* Python **3.9+**
* Microphone (for voice input)
* Speakers (for TTS)

---

### 2ï¸âƒ£ Install Ollama (Required)

This app **requires Ollama running locally**.

ğŸ‘‰ Download & install Ollama:
[https://ollama.com](https://ollama.com)

After installation, pull a model:

```bash
ollama pull llama3
```

Make sure Ollama is running:

```bash
ollama serve
```

Default API used:

```
http://localhost:11434
```

---

### 3ï¸âƒ£ Python Dependencies

Install all required Python libraries:

```bash
pip install PyQt6 requests speechrecognition pyttsx3 PyPDF2 python-docx pyaudio
```

âš ï¸ **Important (Windows users)**
If `pyaudio` fails:

```bash
pip install pipwin
pipwin install pyaudio
```

---

## ğŸš€ How to Run the Application

### Step 1: Clone / Download Project

Place `chat_bot.py` in a project folder.

### Step 2: Start Ollama

```bash
ollama serve
```

### Step 3: Run the App

```bash
python chat_bot.py
```

The **Local AI Assistant window** will open.

---

## ğŸ§ª How to Use

### ğŸ”¹ Select AI Model

* Models are auto-loaded from Ollama
* Use the **dropdown** at the top to switch models

### ğŸ”¹ Start Chat

* Click **â• New Chat**
* Type your question and press **Send**

### ğŸ”¹ Voice Input

* Click **ğŸ¤ Start Voice**
* Speak naturally
* Click **â›” Stop Voice** to stop listening

### ğŸ”¹ Text-to-Speech

* Click **ğŸ”Š Read** on AI responses
* Click **â›” Stop** to stop speaking

### ğŸ”¹ Upload Documents

Supported:

* `.txt`
* `.pdf`
* `.docx`

Uploaded content is inserted into the input box for querying.

---

## ğŸ“ Supported File Types

| File Type | Support                  |
| --------- | ------------------------ |
| `.txt`    | âœ…                        |
| `.pdf`    | âœ… (PyPDF2 required)      |
| `.docx`   | âœ… (python-docx required) |
| Others    | âŒ                        |

---

## ğŸ› ï¸ Build Executable (Optional)

To convert into a standalone `.exe` (Windows):

### Install PyInstaller

```bash
pip install pyinstaller
```

### Build

```bash
pyinstaller --onefile --windowed chat_bot.py
```

Output will be in:

```
dist/chat_bot.exe
```

---

## âš ï¸ Common Issues & Fixes

### âŒ Ollama Offline

**Error:** `ğŸ”´ Offline`

* Make sure Ollama is running
* Check: `http://localhost:11434/api/tags`

---

### âŒ No Models Found

Run:

```bash
ollama pull llama3
```

---

### âŒ Microphone Not Working

* Ensure mic permission is enabled
* Test mic in system settings
* Install correct `pyaudio`

---

### âŒ PDF/DOCX Not Reading

Install missing libs:

```bash
pip install PyPDF2 python-docx
```

---

## ğŸ” Privacy & Security

* AI runs **100% locally**
* No chat data is uploaded
* Only voice recognition uses Google Speech API

---

